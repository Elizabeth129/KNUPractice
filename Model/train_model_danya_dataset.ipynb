{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09c79985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291e0b5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion          ID                          Date     Query  \\\n",
       "0              0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1              0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2              0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3              0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599995        4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996        4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997        4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998        4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  Author                                               Text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = \"cp1252\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b902e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>http://twitpic.com/2y1zl - Awww, that's a bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>I dived many times for the ball. Managed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion          ID                          Date     Query  \\\n",
       "0              0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1              0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2              0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3              0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599995        4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996        4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997        4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998        4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  Author                                               Text  \n",
       "0        _TheSpecialOne_    http://twitpic.com/2y1zl - Awww, that's a bu...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus    I dived many times for the ball. Managed to ...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli    no, it's not behaving at all. i'm mad. why a...  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris                                     happy           \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing hashtags and mentions\n",
    "def remove_hashatags_and_mentions(text):\n",
    "    return re.sub(r'#\\w*', r' ', re.sub(r'@\\w*', r' ', str(text)))\n",
    "\n",
    "df.Text = df.Text.apply(remove_hashatags_and_mentions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9928084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>httptwitpiccom2y1zl  Awww thats a bummer  Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>I dived many times for the ball Managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>no its not behaving at all im mad why am i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up Having no school is the best feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDBcom  Very cool to hear old Walt intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover Ask me fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time Tup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion          ID                          Date     Query  \\\n",
       "0              0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1              0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2              0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3              0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4              0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...          ...         ...                           ...       ...   \n",
       "1599995        4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996        4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997        4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998        4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  Author                                               Text  \n",
       "0        _TheSpecialOne_    httptwitpiccom2y1zl  Awww thats a bummer  Yo...  \n",
       "1          scotthamilton  is upset that he cant update his Facebook by t...  \n",
       "2               mattycus    I dived many times for the ball Managed to s...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli    no its not behaving at all im mad why am i h...  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up Having no school is the best feel...  \n",
       "1599996      TheWDBoards  TheWDBcom  Very cool to hear old Walt intervie...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover Ask me fo...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time Tup...  \n",
       "1599999   RyanTrevMorris                                     happy           \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df.Text = df.Text.apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceed0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "\n",
    "untokenized_texts = np.array(df.Text)\n",
    "emotions = np.array(df.Emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1088c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193514it [01:13, 16135.53it/s]\n"
     ]
    }
   ],
   "source": [
    "english_embedding_dict = {}\n",
    "with open(\"glove.twitter.27B.200d.txt\", \"r\", encoding=\"utf-8\") as english_glove:\n",
    "    for line in tqdm(english_glove):\n",
    "        values = line.split()\n",
    "        word = remove_punctuation(values[0])\n",
    "        vectors = np.asarray(values[1:], 'float32')\n",
    "        english_embedding_dict[word] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc73fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93730a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1600000/1600000 [00:06<00:00, 236191.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 1600000/1600000 [00:05<00:00, 306333.52it/s]\n"
     ]
    }
   ],
   "source": [
    "word_cnt = dict()\n",
    "for text in tqdm(untokenized_texts):\n",
    "    for word in text.split():\n",
    "        word_cnt[word] = word_cnt.get(word, 0) + 1\n",
    "clean_texts = []\n",
    "for text in tqdm(untokenized_texts):\n",
    "    clean_text = ' '.join([word for word in text.split() if word_cnt[word] > 10])\n",
    "    clean_texts.append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "325d3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 29342/29342 [00:00<00:00, 376184.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(clean_texts)\n",
    "padded_sequences = pad_sequences(tokenizer.texts_to_sequences(clean_texts), padding = 'post')\n",
    "max_len = padded_sequences.shape[1]\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_LEN))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_matrix[i] = english_embedding_dict.get(word, np.zeros(EMBEDDING_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "945ec038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    len(word_index) + 1,\n",
    "    EMBEDDING_LEN,\n",
    "    embeddings_initializer=Constant(embedding_matrix),\n",
    "    input_length=max_len,\n",
    "    trainable=False,\n",
    "))\n",
    "model.add(LSTM(500))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(500))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(learning_rate=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "917910f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 40, 200)           5868600   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 500)               1402000   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 7,521,601\n",
      "Trainable params: 1,653,001\n",
      "Non-trainable params: 5,868,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82500bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, texts_test, values_train, values_test = train_test_split(padded_sequences, emotions, test_size = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e3d2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 1.3294 - accuracy: 0.3533\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 1.3013 - accuracy: 0.3590: 36s - loss: 1.2 - ETA: 30s -  - ETA: 27s  -  - ETA: 20s - loss: 1.291 - ETA: 18 - ETA: 15s - loss: 1.2933 - accuracy: 0\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 1.2818 - accuracy: 0.3639: 31s - loss: 1 - ETA: 0s - loss: 1.280\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 1.2482 - accuracy: 0.37024s - - ETA: 1s - loss:\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 1.2320 - accuracy: 0.3723\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 1.2001 - accuracy: 0.3776\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 1.1921 - accuracy: 0.3794\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 1.1555 - accuracy: 0.3856: 13s -  - ETA: 10s - loss: 1.1475  - ETA: 7s - loss: 1.1510  - ETA: 6s - loss: 1.153 - ETA: 5s - loss: 1.1563 - ac - ETA: 4s - ETA: 3s - loss:\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 1.1350 - accuracy: 0.39051s - loss: 1.1323 - accuracy - ETA: 1s - loss: 1.1325 - accuracy:  - ETA: 0s - loss: 1.133\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 1.1105 - accuracy: 0.39343s -\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 1.0981 - accuracy: 0.3959\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 1.0682 - accuracy: 0.3996: 16s - loss: \n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 1.0439 - accuracy: 0.4046\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 1.0287 - accuracy: 0.4077\n",
      "Epoch 15/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 1.0167 - accuracy: 0.4094\n",
      "Epoch 16/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.9979 - accuracy: 0.4126\n",
      "Epoch 17/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.9770 - accuracy: 0.4151\n",
      "Epoch 18/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.9542 - accuracy: 0.4175\n",
      "Epoch 19/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.9514 - accuracy: 0.41973s - los\n",
      "Epoch 20/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.9324 - accuracy: 0.4224\n",
      "Epoch 21/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.9132 - accuracy: 0.4245\n",
      "Epoch 22/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.8974 - accuracy: 0.42710s - loss: 0.8971 \n",
      "Epoch 23/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.8953 - accuracy: 0.4279\n",
      "Epoch 24/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.8823 - accuracy: 0.4296\n",
      "Epoch 25/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.8566 - accuracy: 0.4332\n",
      "Epoch 26/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.8498 - accuracy: 0.4335\n",
      "Epoch 27/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.8359 - accuracy: 0.4356\n",
      "Epoch 28/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.8336 - accuracy: 0.4362\n",
      "Epoch 29/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.8174 - accuracy: 0.4383\n",
      "Epoch 30/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.8199 - accuracy: 0.4378\n",
      "Epoch 31/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.7936 - accuracy: 0.4413\n",
      "Epoch 32/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.7892 - accuracy: 0.4422\n",
      "Epoch 33/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.7810 - accuracy: 0.4436\n",
      "Epoch 34/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.7714 - accuracy: 0.4446\n",
      "Epoch 35/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.7704 - accuracy: 0.4448\n",
      "Epoch 36/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.7624 - accuracy: 0.4452\n",
      "Epoch 37/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.7543 - accuracy: 0.4463\n",
      "Epoch 38/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.7355 - accuracy: 0.4487\n",
      "Epoch 39/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.7327 - accuracy: 0.4495\n",
      "Epoch 40/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.7280 - accuracy: 0.4495\n",
      "Epoch 41/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.7159 - accuracy: 0.4518\n",
      "Epoch 42/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.7182 - accuracy: 0.4511\n",
      "Epoch 43/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.7064 - accuracy: 0.4522\n",
      "Epoch 44/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6969 - accuracy: 0.4534\n",
      "Epoch 45/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.7105 - accuracy: 0.4523\n",
      "Epoch 46/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.6811 - accuracy: 0.4547\n",
      "Epoch 47/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6889 - accuracy: 0.4550\n",
      "Epoch 48/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6763 - accuracy: 0.4563\n",
      "Epoch 49/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6817 - accuracy: 0.4551\n",
      "Epoch 50/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6722 - accuracy: 0.4566\n",
      "Epoch 51/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.6717 - accuracy: 0.4569\n",
      "Epoch 52/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6668 - accuracy: 0.4577\n",
      "Epoch 53/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.6510 - accuracy: 0.4593\n",
      "Epoch 54/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.6576 - accuracy: 0.4589\n",
      "Epoch 55/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6435 - accuracy: 0.45951s - loss: 0\n",
      "Epoch 56/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6298 - accuracy: 0.4613\n",
      "Epoch 57/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6410 - accuracy: 0.4600\n",
      "Epoch 58/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6309 - accuracy: 0.4614\n",
      "Epoch 59/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6349 - accuracy: 0.4610\n",
      "Epoch 60/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6242 - accuracy: 0.4619\n",
      "Epoch 61/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6219 - accuracy: 0.4625\n",
      "Epoch 62/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6205 - accuracy: 0.46261s -\n",
      "Epoch 63/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.6250 - accuracy: 0.4621\n",
      "Epoch 64/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.6108 - accuracy: 0.4635\n",
      "Epoch 65/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6003 - accuracy: 0.4644\n",
      "Epoch 66/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.6067 - accuracy: 0.4640\n",
      "Epoch 67/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.5909 - accuracy: 0.4651\n",
      "Epoch 68/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.6073 - accuracy: 0.4637\n",
      "Epoch 69/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.6020 - accuracy: 0.46441s - l\n",
      "Epoch 70/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.5848 - accuracy: 0.4657\n",
      "Epoch 71/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.5856 - accuracy: 0.4658\n",
      "Epoch 72/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.5892 - accuracy: 0.4651\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5862 - accuracy: 0.4662\n",
      "Epoch 74/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.5848 - accuracy: 0.4659\n",
      "Epoch 75/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.5696 - accuracy: 0.4670\n",
      "Epoch 76/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5698 - accuracy: 0.4666\n",
      "Epoch 77/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.5728 - accuracy: 0.4661\n",
      "Epoch 78/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.5783 - accuracy: 0.4660\n",
      "Epoch 79/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.5698 - accuracy: 0.4664\n",
      "Epoch 80/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.5649 - accuracy: 0.4671\n",
      "Epoch 81/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.5509 - accuracy: 0.4685\n",
      "Epoch 82/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.5492 - accuracy: 0.4682\n",
      "Epoch 83/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5614 - accuracy: 0.4670\n",
      "Epoch 84/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.5473 - accuracy: 0.4683\n",
      "Epoch 85/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5426 - accuracy: 0.4684\n",
      "Epoch 86/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5459 - accuracy: 0.4684\n",
      "Epoch 87/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5454 - accuracy: 0.4681\n",
      "Epoch 88/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5350 - accuracy: 0.46913s - ETA: 1s\n",
      "Epoch 89/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5365 - accuracy: 0.4681\n",
      "Epoch 90/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5352 - accuracy: 0.4684\n",
      "Epoch 91/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5383 - accuracy: 0.4682\n",
      "Epoch 92/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.5315 - accuracy: 0.4686\n",
      "Epoch 93/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.5204 - accuracy: 0.4698: 30s - loss: 0.5148 - accuracy: 0.471 - ETA: 30s - loss: 0.5144 - ac - ETA: 29s - loss: 0.5130 - accur - ETA: 28s - - ETA: 25s - loss: 0.5151 - accuracy: 0.4  - ETA: 16s - loss: 0.5116 - accu - ETA: 15s - loss: 0.51 - ETA: 13s - loss: 0.5115 - accuracy: 0 - ETA: 12s - loss: 0.5111 - acc\n",
      "Epoch 94/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.5199 - accuracy: 0.46981s - loss: 0.5197 - accuracy - ETA: 1s -\n",
      "Epoch 95/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.5197 - accuracy: 0.46973s -\n",
      "Epoch 96/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.5212 - accuracy: 0.4694: 40s - loss: 0.5062 - accuracy: 0. - ETA: 40s - loss:  - ETA: 38s - loss: 0.5136 - ac - ETA:  - ETA: 33s - loss: \n",
      "Epoch 97/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.5121 - accuracy: 0.47040s - loss: 0.5120 - \n",
      "Epoch 98/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.5147 - accuracy: 0.4700: 42s - loss: 0.5140 - accuracy - ETA: 4 - ETA: 39s - loss: 0.4886 - a - ETA: 25s - loss: 0. - ETA: 10 - ETA: 8s - loss: 0.506 - ETA: 7s - loss: 0.5087 - accuracy - ETA: 7s - los\n",
      "Epoch 99/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.5086 - accuracy: 0.4710\n",
      "Epoch 100/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.5176 - accuracy: 0.4699\n",
      "Epoch 101/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4978 - accuracy: 0.4716: 14s - loss: 0.4938 - acc - ETA: 1s - loss: 0.4968 - ac - ETA: 0s - loss: 0.4967 - \n",
      "Epoch 102/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.5037 - accuracy: 0.47091s\n",
      "Epoch 103/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.4956 - accuracy: 0.4715: 29s - loss: 0.4835 - accuracy: 0 - - ETA: 20s - loss: 0.4885 - acc -\n",
      "Epoch 104/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4963 - accuracy: 0.4718: 39s - loss: 0.4945 - acc - ETA:  -\n",
      "Epoch 105/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.4840 - accuracy: 0.4728\n",
      "Epoch 106/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.4947 - accuracy: 0.4715: 43s -  - ETA: 28s - loss: 0.4940 - acc - ETA: 26 - ETA: 19s - loss: 0.4921 - accuracy:  - ETA: 18s - loss: 0.4913  - ETA: 4s - loss: 0.4923 - accuracy - ETA: 4s - loss: 0 - ETA: 1s - loss: - ETA: 0s - loss: 0.4947 - accuracy: 0.\n",
      "Epoch 107/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.4922 - accuracy: 0.4719: 43s - loss: 0.4967 - accuracy: 0.4 - ETA: 42s - loss\n",
      "Epoch 108/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.4848 - accuracy: 0.4727\n",
      "Epoch 109/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4920 - accuracy: 0.4716: 39s - loss: 0.4457 - accura - ETA: 39s - loss: 0.4621 - accuracy:  - ETA: 3s - los\n",
      "Epoch 110/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.4852 - accuracy: 0.4723: 40s - lo - ETA: 1s - loss: 0\n",
      "Epoch 111/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.4717 - accuracy: 0.47344s - loss: 0.4679 - accuracy: 0. - E\n",
      "Epoch 112/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4766 - accuracy: 0.4735: 23s - loss: 0.4829 - accu - ETA: 22s - loss: 0.4837  - ETA: 16s - loss: 0.4878 \n",
      "Epoch 113/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.4732 - accuracy: 0.4737\n",
      "Epoch 114/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4759 - accuracy: 0.4732: 42s - ETA: 23s - loss: 0.4625 - accuracy: 0.\n",
      "Epoch 115/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4661 - accuracy: 0.47420s - loss: 0.4658 - accuracy - ETA: 0s - loss: 0.4662 - accuracy: 0.\n",
      "Epoch 116/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4641 - accuracy: 0.4743\n",
      "Epoch 117/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.4638 - accuracy: 0.4737\n",
      "Epoch 118/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4624 - accuracy: 0.47370s - loss: 0.4619 - accu\n",
      "Epoch 119/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4616 - accuracy: 0.4739\n",
      "Epoch 120/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4562 - accuracy: 0.4741\n",
      "Epoch 121/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4534 - accuracy: 0.4746\n",
      "Epoch 122/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4542 - accuracy: 0.4742\n",
      "Epoch 123/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.4483 - accuracy: 0.4747\n",
      "Epoch 124/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4502 - accuracy: 0.47421s - l\n",
      "Epoch 125/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4446 - accuracy: 0.47474s - loss: 0.4434 - accu\n",
      "Epoch 126/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4349 - accuracy: 0.4752\n",
      "Epoch 127/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4397 - accuracy: 0.47480s - loss: 0.4390 - accuracy\n",
      "Epoch 128/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4359 - accuracy: 0.47482s - loss: 0.4344 - accuracy: \n",
      "Epoch 129/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4347 - accuracy: 0.47501s\n",
      "Epoch 130/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4292 - accuracy: 0.4756\n",
      "Epoch 131/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.4267 - accuracy: 0.4757: 37s - loss:  - ETA: 35s - loss: 0.4217 - ETA: 0s - loss: 0.4267 - accura\n",
      "Epoch 132/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4240 - accuracy: 0.4756\n",
      "Epoch 133/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4299 - accuracy: 0.4746\n",
      "Epoch 134/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4192 - accuracy: 0.4759: 41s - loss: 0.4109 - accuracy: 0. - ETA: 41s - loss: 0.404 - ETA:  - ETA: 4s - loss: - ETA: 1s - los\n",
      "Epoch 135/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4146 - accuracy: 0.4755: 39s - loss: 0.4008 - ac - ETA: 37s - loss: 0.3893 - accurac - ETA: 37s - loss: - ETA: 30s - loss: - ETA: 28s - loss: 0.4049 - accuracy: 0. - ETA: - ETA: 15s - loss: 0.4117 - accuracy: 0. - ETA: - ETA: 0s - loss: 0.4153 \n",
      "Epoch 136/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4137 - accuracy: 0.4757: 42s - loss: 0 - ETA: 39s - loss: 0.3760 - - E - ETA: 5s - loss: 0.4128  - ETA: 4s - loss: 0.4128 \n",
      "Epoch 137/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4090 - accuracy: 0.4761\n",
      "Epoch 138/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4106 - accuracy: 0.47625s - loss: 0.4052 - accuracy - ETA:  - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.4105 - accuracy: \n",
      "Epoch 139/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.4067 - accuracy: 0.4758: 1 - ETA - ETA: 6s - loss: 0.4066 - accuracy:  - ETA: 6s - loss: 0.4071 - accuracy: 0.47 - ETA: 5s - loss: 0.4069 - ac - ETA: 1s - los\n",
      "Epoch 140/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4015 - accuracy: 0.4762\n",
      "Epoch 141/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4013 - accuracy: 0.4762\n",
      "Epoch 142/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.4000 - accuracy: 0.4766\n",
      "Epoch 143/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.4013 - accuracy: 0.47620s - loss: 0.4010 - accuracy\n",
      "Epoch 144/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3912 - accuracy: 0.4768: 25s - loss: 0.3888 - accur - ETA: 20s - loss: 0.3939  - ETA: 2s - loss: 0 - ETA: 0s - loss: 0.3\n",
      "Epoch 145/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3862 - accuracy: 0.47710s - loss: 0.3866 - accuracy: 0. - ETA: 0s - loss: 0.3865 \n",
      "Epoch 146/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3928 - accuracy: 0.47654s - los - ETA: 2s - loss: 0.3946 \n",
      "Epoch 147/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3918 - accuracy: 0.4760\n",
      "Epoch 148/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3803 - accuracy: 0.4769\n",
      "Epoch 149/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3763 - accuracy: 0.4772\n",
      "Epoch 150/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3874 - accuracy: 0.4760: 25s - lo\n",
      "Epoch 151/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.3774 - accuracy: 0.47680s - loss: 0.3779 - accuracy\n",
      "Epoch 152/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3766 - accuracy: 0.4772\n",
      "Epoch 153/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.3674 - accuracy: 0.4778\n",
      "Epoch 154/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.3720 - accuracy: 0.4774\n",
      "Epoch 155/1000\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.3620 - accuracy: 0.4775\n",
      "Epoch 156/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.3659 - accuracy: 0.47740s - loss: 0.3654 - \n",
      "Epoch 157/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.3601 - accuracy: 0.4778\n",
      "Epoch 158/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3586 - accuracy: 0.47761s - loss: 0.3584 -  - ETA: 1s - loss: 0\n",
      "Epoch 159/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.3556 - accuracy: 0.4780\n",
      "Epoch 160/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.3519 - accuracy: 0.4780\n",
      "Epoch 161/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.3540 - accuracy: 0.4780\n",
      "Epoch 162/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.3497 - accuracy: 0.47841s - loss: 0 - ETA: 0s - loss: 0.3498 - accura\n",
      "Epoch 163/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.3473 - accuracy: 0.4781: 14\n",
      "Epoch 164/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.3464 - accuracy: 0.4787\n",
      "Epoch 165/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.3398 - accuracy: 0.4791\n",
      "Epoch 166/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3424 - accuracy: 0.4787\n",
      "Epoch 167/1000\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.3377 - accuracy: 0.4784\n",
      "Epoch 168/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3340 - accuracy: 0.4796\n",
      "Epoch 169/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3342 - accuracy: 0.4793\n",
      "Epoch 170/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3329 - accuracy: 0.4798\n",
      "Epoch 171/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3326 - accuracy: 0.4789\n",
      "Epoch 172/1000\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.3235 - accuracy: 0.4800\n",
      "Epoch 173/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.3208 - accuracy: 0.4801\n",
      "Epoch 174/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.3255 - accuracy: 0.4796\n",
      "Epoch 175/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3253 - accuracy: 0.4797\n",
      "Epoch 176/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3183 - accuracy: 0.4800\n",
      "Epoch 177/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.3252 - accuracy: 0.4795\n",
      "Epoch 178/1000\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.3117 - accuracy: 0.4802\n",
      "Epoch 179/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3093 - accuracy: 0.4813\n",
      "Epoch 180/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3141 - accuracy: 0.4805\n",
      "Epoch 181/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3166 - accuracy: 0.4797\n",
      "Epoch 182/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3087 - accuracy: 0.4805\n",
      "Epoch 183/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3018 - accuracy: 0.4811\n",
      "Epoch 184/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3019 - accuracy: 0.4812\n",
      "Epoch 185/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3032 - accuracy: 0.4811\n",
      "Epoch 186/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.2963 - accuracy: 0.4815\n",
      "Epoch 187/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.2983 - accuracy: 0.4814\n",
      "Epoch 188/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.3017 - accuracy: 0.4811\n",
      "Epoch 189/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2933 - accuracy: 0.4818\n",
      "Epoch 190/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.3017 - accuracy: 0.4806\n",
      "Epoch 191/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2854 - accuracy: 0.4824\n",
      "Epoch 192/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2945 - accuracy: 0.4813\n",
      "Epoch 193/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2988 - accuracy: 0.4807\n",
      "Epoch 194/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.2848 - accuracy: 0.4821\n",
      "Epoch 195/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.2897 - accuracy: 0.4818\n",
      "Epoch 196/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.2804 - accuracy: 0.4825\n",
      "Epoch 197/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2874 - accuracy: 0.4816\n",
      "Epoch 198/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2838 - accuracy: 0.4825\n",
      "Epoch 199/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2770 - accuracy: 0.4827\n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2772 - accuracy: 0.4825\n",
      "Epoch 201/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2853 - accuracy: 0.48190s - loss: 0.2849 - accura\n",
      "Epoch 202/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2702 - accuracy: 0.4828\n",
      "Epoch 203/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.2779 - accuracy: 0.4823\n",
      "Epoch 204/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2740 - accuracy: 0.4830\n",
      "Epoch 205/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2768 - accuracy: 0.4822\n",
      "Epoch 206/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2762 - accuracy: 0.4824\n",
      "Epoch 207/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2659 - accuracy: 0.4833\n",
      "Epoch 208/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2648 - accuracy: 0.4832\n",
      "Epoch 209/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2723 - accuracy: 0.4827\n",
      "Epoch 210/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2687 - accuracy: 0.4826\n",
      "Epoch 211/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2672 - accuracy: 0.4829\n",
      "Epoch 212/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2659 - accuracy: 0.4828\n",
      "Epoch 213/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2650 - accuracy: 0.4832\n",
      "Epoch 214/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.2608 - accuracy: 0.4837\n",
      "Epoch 215/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2617 - accuracy: 0.4837\n",
      "Epoch 216/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2586 - accuracy: 0.4835\n",
      "Epoch 217/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.2611 - accuracy: 0.4833\n",
      "Epoch 218/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2507 - accuracy: 0.4842\n",
      "Epoch 219/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2622 - accuracy: 0.4832\n",
      "Epoch 220/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2607 - accuracy: 0.4834\n",
      "Epoch 221/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.2529 - accuracy: 0.48381s - los\n",
      "Epoch 222/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2609 - accuracy: 0.4835\n",
      "Epoch 223/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2552 - accuracy: 0.48350s - loss: 0.2548 - \n",
      "Epoch 224/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2492 - accuracy: 0.4839\n",
      "Epoch 225/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.2534 - accuracy: 0.4837\n",
      "Epoch 226/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2455 - accuracy: 0.4842\n",
      "Epoch 227/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2443 - accuracy: 0.4845\n",
      "Epoch 228/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2436 - accuracy: 0.4846\n",
      "Epoch 229/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2480 - accuracy: 0.4839\n",
      "Epoch 230/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2456 - accuracy: 0.4844\n",
      "Epoch 231/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2432 - accuracy: 0.4844\n",
      "Epoch 232/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2399 - accuracy: 0.4847\n",
      "Epoch 233/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2367 - accuracy: 0.4849\n",
      "Epoch 234/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2488 - accuracy: 0.4838\n",
      "Epoch 235/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.2434 - accuracy: 0.4840\n",
      "Epoch 236/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2441 - accuracy: 0.4843\n",
      "Epoch 237/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2321 - accuracy: 0.4852\n",
      "Epoch 238/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2387 - accuracy: 0.4851\n",
      "Epoch 239/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.2347 - accuracy: 0.4849\n",
      "Epoch 240/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2322 - accuracy: 0.4852\n",
      "Epoch 241/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.2320 - accuracy: 0.4851\n",
      "Epoch 242/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.2354 - accuracy: 0.4849\n",
      "Epoch 243/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.2320 - accuracy: 0.4850: 24s - loss: 0.2306 - accuracy: 0.485 - ETA: 24s - loss:  - E - ETA: 1s - loss: 0.2316 - ac - ETA: 0s - loss: 0.2320 - \n",
      "Epoch 244/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.2422 - accuracy: 0.4838\n",
      "Epoch 245/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2309 - accuracy: 0.4849\n",
      "Epoch 246/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2296 - accuracy: 0.4851\n",
      "Epoch 247/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2289 - accuracy: 0.4851\n",
      "Epoch 248/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2237 - accuracy: 0.4857\n",
      "Epoch 249/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2311 - accuracy: 0.4847\n",
      "Epoch 250/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2313 - accuracy: 0.4849: 29s - loss: 0.2228 - - ETA: 28s - loss: 0.2259 -  - ETA: 26s - loss: 0.2283 - accura  - ETA: 21s - los\n",
      "Epoch 251/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2265 - accuracy: 0.4852: 40s - l -  - ETA: 26s - loss: 0.2188  - ETA: 24s - loss: 0.2257 - ac - ETA: 23s - - ETA: 20s - loss: 0 - ETA: 1s\n",
      "Epoch 252/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2225 - accuracy: 0.4857\n",
      "Epoch 253/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2291 - accuracy: 0.4849TA: 7s - loss: 0.2260 - accuracy: 0.48 - ETA\n",
      "Epoch 254/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2220 - accuracy: 0.4856\n",
      "Epoch 255/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2221 - accuracy: 0.4855: 38s - los - ETA: 36s - loss: 0.2112 - accura - ETA: 35s - loss: 0.2149 - accu - ETA: 34s - ETA: 5s - loss: 0.2248 - accuracy: 0. - ETA\n",
      "Epoch 256/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2181 - accuracy: 0.4858\n",
      "Epoch 257/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2264 - accuracy: 0.48521s - loss:\n",
      "Epoch 258/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2237 - accuracy: 0.4852\n",
      "Epoch 259/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2232 - accuracy: 0.4854\n",
      "Epoch 260/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2162 - accuracy: 0.4860\n",
      "Epoch 261/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2183 - accuracy: 0.48560s - loss: 0.2181 - accuracy: \n",
      "Epoch 262/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2173 - accuracy: 0.4858: 36s - lo - ETA: 33s - loss: 0.2305 - acc - ETA: 32s - loss: 0.2328 - accur - ETA:  - ETA: 28s - loss: 0.2281 - accu - ETA: 27s - loss: 0.226 - ETA: 25s - - ETA: 22s -  - ETA: 4s - loss: 0.2192 - accuracy\n",
      "Epoch 263/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2093 - accuracy: 0.4863: 40s - loss: 0.2320  - ETA: 38s - lo - ETA: 31s - loss - ETA: 29s - - ETA: 26s - loss  - ETA: 19s - loss: 0.2102 - accuracy: 0 - ETA: 19s - loss: 0.2103 - accu - ETA: 3s - los - ETA: 2s - loss: 0.2 - ETA: 1s - loss: 0.2096 - accuracy: 0. - ETA: 1s - loss: 0.2096 - accuracy:  - ETA: 1s - loss: 0\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2171 - accuracy: 0.4856: 37s - loss: - ETA: 31s  - ETA: 28s  - ETA: 25s -  - ETA: 22s - loss: 0.2097 - accurac - ETA: 21s - loss: 0.2093 - accuracy:  - ET - ETA: 17s - l\n",
      "Epoch 265/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2148 - accuracy: 0.4858: 26s - lo - ETA: 24s - loss: 0.2183 - accuracy: 0. - ETA: 23s - loss: 0.2184 - accur\n",
      "Epoch 266/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2124 - accuracy: 0.4861\n",
      "Epoch 267/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2126 - accuracy: 0.4860\n",
      "Epoch 268/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2120 - accuracy: 0.4858\n",
      "Epoch 269/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2087 - accuracy: 0.4862: 11s - loss: 0.2031 - accuracy: 0. - ETA: 10s - loss: 0.2032 - accuracy: 0\n",
      "Epoch 270/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2118 - accuracy: 0.4858: 33s - loss: 0.2079 - accuracy: 0.488 - - ETA: 21s - ETA: \n",
      "Epoch 271/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2040 - accuracy: 0.4864\n",
      "Epoch 272/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2062 - accuracy: 0.4865\n",
      "Epoch 273/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2062 - accuracy: 0.4863\n",
      "Epoch 274/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1981 - accuracy: 0.4869\n",
      "Epoch 275/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2077 - accuracy: 0.4861 ETA: 3s -\n",
      "Epoch 276/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.2083 - accuracy: 0.4859\n",
      "Epoch 277/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1996 - accuracy: 0.4869: 29s - loss: 0 - ET - ETA:  - ETA: 15s - l - ETA: 1 - ETA: \n",
      "Epoch 278/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1987 - accuracy: 0.4867: - ETA -\n",
      "Epoch 279/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1980 - accuracy: 0.48675s - loss: 0.1981 - accuracy - ETA - E\n",
      "Epoch 280/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2019 - accuracy: 0.48622s - loss: 0.2005 - ac\n",
      "Epoch 281/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.2003 - accuracy: 0.4865: 32s - loss: 0.20 - ETA: - ETA: 27s - loss: 0.2076 - a - ETA: 26\n",
      "Epoch 282/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1993 - accuracy: 0.4868: 41s - loss: 0.20 - ETA: 39s - lo - ETA: 32s - loss: 0.1 - ETA: 30s - - ETA: 23s  - ETA: 1 - ETA: 1s - l\n",
      "Epoch 283/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1953 - accuracy: 0.4868: 21s - loss: 0.1882 - accuracy: 0 - ETA: 21s - loss: \n",
      "Epoch 284/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1948 - accuracy: 0.48700s - loss: 0.1950 - \n",
      "Epoch 285/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1997 - accuracy: 0.48631s - los\n",
      "Epoch 286/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1864 - accuracy: 0.4876: 27s -  - ETA: 25s - loss: 0.1876 - accura - ETA: 24s - loss: 0.1877 - accuracy: 0.486 - E - ETA: 16s - lo -  - E - ETA: 5s - loss: 0.1872 - accura - ETA: 5s - - ETA: 3s - loss: 0.1870  - ETA: 1s - loss: 0\n",
      "Epoch 287/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1913 - accuracy: 0.4872ETA: 3s -\n",
      "Epoch 288/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1995 - accuracy: 0.4864\n",
      "Epoch 289/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1892 - accuracy: 0.4874\n",
      "Epoch 290/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1885 - accuracy: 0.48753s - los\n",
      "Epoch 291/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1954 - accuracy: 0.4866\n",
      "Epoch 292/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1882 - accuracy: 0.4874: 24s - loss: 0.1856 - - ETA: 3s - loss: 0.1872 - ac - ETA: 3s - loss: - ETA: 0s - loss: 0.1882 - accuracy: 0.\n",
      "Epoch 293/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1857 - accuracy: 0.48753s - los\n",
      "Epoch 294/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1808 - accuracy: 0.48780s - loss: 0.1810 - accura\n",
      "Epoch 295/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1831 - accuracy: 0.4877- ETA: 27s - loss: 0.1779  - ETA: 2\n",
      "Epoch 296/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1983 - accuracy: 0.4864: 33s - loss: 0.2203 - accura - ETA: - ETA: 0s - loss: 0.1981 \n",
      "Epoch 297/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1887 - accuracy: 0.4872: 3s -\n",
      "Epoch 298/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1771 - accuracy: 0.48811s - los\n",
      "Epoch 299/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1781 - accuracy: 0.4880\n",
      "Epoch 300/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1806 - accuracy: 0.4877\n",
      "Epoch 301/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1831 - accuracy: 0.4877: 36s - loss: 0.1844 - - ETA: 34s - loss: 0.186 - ETA: 32s - ETA: 29s - loss: - ETA: 27s - ETA: 0s - loss: 0.1832 - ac\n",
      "Epoch 302/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1823 - accuracy: 0.4876\n",
      "Epoch 303/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1841 - accuracy: 0.4876: 31s - - E - E - ETA: 1s - loss:\n",
      "Epoch 304/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1776 - accuracy: 0.48781s - los - ETA: 0s - loss: 0.1776 - accuracy\n",
      "Epoch 305/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1755 - accuracy: 0.48813s - loss: 0.1757 - accuracy: 0. - ETA: 3s - loss: 0.1757 - accu - ETA: 0s - loss: 0.1760 - ac\n",
      "Epoch 306/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1754 - accuracy: 0.48792s - loss: 0.1741 - ac\n",
      "Epoch 307/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1774 - accuracy: 0.4878: 25s - loss: 0.1717 - accuracy: 0.488 - ETA: 25s - loss: 0.1716 - accuracy - ETA: 24s - loss: 0.173 - ETA: 22s - loss: 0.1734 - accuracy: 0. - ETA: 14s  - ETA: 4s - loss: 0.1741 - accuracy\n",
      "Epoch 308/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1803 - accuracy: 0.48761s - loss: 0 - ETA: 0s - loss: 0.180\n",
      "Epoch 309/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1695 - accuracy: 0.4887A: 4s - ETA: 0s - loss: 0.1695 - \n",
      "Epoch 310/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1736 - accuracy: 0.4882\n",
      "Epoch 311/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1722 - accuracy: 0.4881 ETA: 0s - loss: 0.1720 \n",
      "Epoch 312/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1815 - accuracy: 0.4876\n",
      "Epoch 313/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1763 - accuracy: 0.48750s - loss: 0.1758 - accu\n",
      "Epoch 314/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1739 - accuracy: 0.4881TA: 15s - los - ETA: 5s - loss: 0.1718 -  - ETA: 4s - loss: 0.1717 - accuracy\n",
      "Epoch 315/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1720 - accuracy: 0.4886\n",
      "Epoch 316/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1722 - accuracy: 0.48824s - los - ETA: 2s - - ETA: 1s - l\n",
      "Epoch 317/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1752 - accuracy: 0.4878\n",
      "Epoch 318/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1727 - accuracy: 0.4881\n",
      "Epoch 319/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1672 - accuracy: 0.4888\n",
      "Epoch 320/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1734 - accuracy: 0.4879\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1756 - accuracy: 0.4880\n",
      "Epoch 322/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1724 - accuracy: 0.4881\n",
      "Epoch 323/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1677 - accuracy: 0.4883: 15s - loss: 0.1691 - accuracy: 0. - ETA: 14s - loss: 0.1691 -  - ET - ETA: 5s - loss: 0.1688 - accuracy: 0. - ETA: 5s - loss: 0.1 - ETA: 4s - los - ETA: 3s - loss:\n",
      "Epoch 324/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1729 - accuracy: 0.4881: 31s -  - ETA: 24s - loss: - ETA: 1s\n",
      "Epoch 325/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1662 - accuracy: 0.4888\n",
      "Epoch 326/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1739 - accuracy: 0.4882\n",
      "Epoch 327/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1660 - accuracy: 0.4886\n",
      "Epoch 328/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1657 - accuracy: 0.4888\n",
      "Epoch 329/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1658 - accuracy: 0.48861s - l\n",
      "Epoch 330/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1673 - accuracy: 0.4886\n",
      "Epoch 331/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1629 - accuracy: 0.4889\n",
      "Epoch 332/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1705 - accuracy: 0.4884\n",
      "Epoch 333/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1668 - accuracy: 0.4886\n",
      "Epoch 334/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1709 - accuracy: 0.4881\n",
      "Epoch 335/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1667 - accuracy: 0.4885\n",
      "Epoch 336/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1701 - accuracy: 0.4883\n",
      "Epoch 337/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1568 - accuracy: 0.4893\n",
      "Epoch 338/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1609 - accuracy: 0.4891\n",
      "Epoch 339/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1598 - accuracy: 0.4892\n",
      "Epoch 340/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1710 - accuracy: 0.48800s - loss: 0.1710 - accura\n",
      "Epoch 341/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1663 - accuracy: 0.4885\n",
      "Epoch 342/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1588 - accuracy: 0.4890\n",
      "Epoch 343/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1557 - accuracy: 0.4894\n",
      "Epoch 344/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1664 - accuracy: 0.4884\n",
      "Epoch 345/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1604 - accuracy: 0.4891\n",
      "Epoch 346/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1607 - accuracy: 0.4889\n",
      "Epoch 347/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1631 - accuracy: 0.4884\n",
      "Epoch 348/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1588 - accuracy: 0.4891\n",
      "Epoch 349/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1593 - accuracy: 0.4890\n",
      "Epoch 350/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1564 - accuracy: 0.4891\n",
      "Epoch 351/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1535 - accuracy: 0.4894\n",
      "Epoch 352/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1612 - accuracy: 0.4887\n",
      "Epoch 353/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1578 - accuracy: 0.4891\n",
      "Epoch 354/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1552 - accuracy: 0.4894\n",
      "Epoch 355/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1568 - accuracy: 0.4895\n",
      "Epoch 356/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1559 - accuracy: 0.48950s - loss: 0.1\n",
      "Epoch 357/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1564 - accuracy: 0.4889\n",
      "Epoch 358/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1538 - accuracy: 0.4894\n",
      "Epoch 359/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1620 - accuracy: 0.4888\n",
      "Epoch 360/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1546 - accuracy: 0.4894\n",
      "Epoch 361/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1567 - accuracy: 0.4893\n",
      "Epoch 362/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1551 - accuracy: 0.4893\n",
      "Epoch 363/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1503 - accuracy: 0.4896\n",
      "Epoch 364/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1525 - accuracy: 0.4893\n",
      "Epoch 365/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1558 - accuracy: 0.4894\n",
      "Epoch 366/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1568 - accuracy: 0.4891\n",
      "Epoch 367/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1586 - accuracy: 0.4889\n",
      "Epoch 368/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1504 - accuracy: 0.4895\n",
      "Epoch 369/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1484 - accuracy: 0.49001s - l\n",
      "Epoch 370/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1563 - accuracy: 0.4891\n",
      "Epoch 371/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1510 - accuracy: 0.4895\n",
      "Epoch 372/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1504 - accuracy: 0.4897\n",
      "Epoch 373/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1547 - accuracy: 0.4893\n",
      "Epoch 374/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1519 - accuracy: 0.4896\n",
      "Epoch 375/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1497 - accuracy: 0.4896\n",
      "Epoch 376/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1473 - accuracy: 0.4898\n",
      "Epoch 377/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1498 - accuracy: 0.4895\n",
      "Epoch 378/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1545 - accuracy: 0.4892\n",
      "Epoch 379/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1465 - accuracy: 0.4900\n",
      "Epoch 380/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1523 - accuracy: 0.4897\n",
      "Epoch 381/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1629 - accuracy: 0.4885\n",
      "Epoch 382/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1509 - accuracy: 0.4897\n",
      "Epoch 383/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1505 - accuracy: 0.4896\n",
      "Epoch 384/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1436 - accuracy: 0.4901\n",
      "Epoch 385/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1520 - accuracy: 0.4896\n",
      "Epoch 386/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1523 - accuracy: 0.4896\n",
      "Epoch 387/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1454 - accuracy: 0.4901\n",
      "Epoch 388/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1535 - accuracy: 0.4893\n",
      "Epoch 389/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1475 - accuracy: 0.4900\n",
      "Epoch 390/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1474 - accuracy: 0.4897\n",
      "Epoch 391/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1510 - accuracy: 0.4895\n",
      "Epoch 392/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1441 - accuracy: 0.4901\n",
      "Epoch 393/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1481 - accuracy: 0.4898\n",
      "Epoch 394/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1456 - accuracy: 0.4902\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1515 - accuracy: 0.4894\n",
      "Epoch 396/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1502 - accuracy: 0.4895\n",
      "Epoch 397/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1492 - accuracy: 0.4894\n",
      "Epoch 398/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1464 - accuracy: 0.4900\n",
      "Epoch 399/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1411 - accuracy: 0.4903\n",
      "Epoch 400/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1488 - accuracy: 0.4897\n",
      "Epoch 401/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1461 - accuracy: 0.4899\n",
      "Epoch 402/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1464 - accuracy: 0.4897\n",
      "Epoch 403/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1454 - accuracy: 0.4900\n",
      "Epoch 404/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1478 - accuracy: 0.4896\n",
      "Epoch 405/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1468 - accuracy: 0.4898\n",
      "Epoch 406/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1446 - accuracy: 0.4900\n",
      "Epoch 407/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1458 - accuracy: 0.4897\n",
      "Epoch 408/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1491 - accuracy: 0.4895\n",
      "Epoch 409/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1433 - accuracy: 0.4901\n",
      "Epoch 410/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1407 - accuracy: 0.4905\n",
      "Epoch 411/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1451 - accuracy: 0.48991s\n",
      "Epoch 412/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1461 - accuracy: 0.4898\n",
      "Epoch 413/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1425 - accuracy: 0.4900\n",
      "Epoch 414/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1464 - accuracy: 0.48980s - loss: 0.1467 - accu\n",
      "Epoch 415/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1451 - accuracy: 0.4899\n",
      "Epoch 416/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1452 - accuracy: 0.48972s - loss: 0.1455 \n",
      "Epoch 417/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1431 - accuracy: 0.4901\n",
      "Epoch 418/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1437 - accuracy: 0.4901: 38 - ETA: 35s - loss: 0.1537 - ET - ETA: 3s - loss: 0.1431  - ETA:  - ETA: 0s - loss: 0.1\n",
      "Epoch 419/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1429 - accuracy: 0.4902\n",
      "Epoch 420/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1408 - accuracy: 0.49050s - loss: 0.1408 - accuracy: 0.\n",
      "Epoch 421/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1443 - accuracy: 0.4899: 28s - l - ETA:  - E - ETA: 4s - loss: 0.1435 - accuracy:  - ETA:  - ETA: 2s - los - ETA: 0s - loss: 0.1\n",
      "Epoch 422/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1484 - accuracy: 0.4897\n",
      "Epoch 423/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1439 - accuracy: 0.4899\n",
      "Epoch 424/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1438 - accuracy: 0.4900\n",
      "Epoch 425/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1386 - accuracy: 0.4905\n",
      "Epoch 426/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1444 - accuracy: 0.4899 - ETA: 0s - loss: 0.1446 - ac\n",
      "Epoch 427/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1412 - accuracy: 0.4904\n",
      "Epoch 428/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1413 - accuracy: 0.4902\n",
      "Epoch 429/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1381 - accuracy: 0.4904\n",
      "Epoch 430/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1440 - accuracy: 0.48991s - loss: 0.1440 - accuracy: 0.48 - ETA: \n",
      "Epoch 431/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1425 - accuracy: 0.4900\n",
      "Epoch 432/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1459 - accuracy: 0.4897\n",
      "Epoch 433/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1394 - accuracy: 0.49021s - loss: 0.1391 - ac - ETA: 1s - loss: 0\n",
      "Epoch 434/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1442 - accuracy: 0.49011s - loss: 0\n",
      "Epoch 435/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1357 - accuracy: 0.4907: 34s - loss:  - ETA: 32s - loss: 0.1441 - ac\n",
      "Epoch 436/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1464 - accuracy: 0.4898\n",
      "Epoch 437/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1428 - accuracy: 0.49010s - loss: 0.1425 - \n",
      "Epoch 438/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1375 - accuracy: 0.4904\n",
      "Epoch 439/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1370 - accuracy: 0.4905\n",
      "Epoch 440/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1439 - accuracy: 0.4900\n",
      "Epoch 441/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1370 - accuracy: 0.4905\n",
      "Epoch 442/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1389 - accuracy: 0.4903\n",
      "Epoch 443/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1367 - accuracy: 0.4905\n",
      "Epoch 444/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1406 - accuracy: 0.49031s - los\n",
      "Epoch 445/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1424 - accuracy: 0.4900\n",
      "Epoch 446/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1371 - accuracy: 0.4906\n",
      "Epoch 447/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1389 - accuracy: 0.4903\n",
      "Epoch 448/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1395 - accuracy: 0.4902\n",
      "Epoch 449/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1375 - accuracy: 0.4903\n",
      "Epoch 450/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1404 - accuracy: 0.4902\n",
      "Epoch 451/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1393 - accuracy: 0.49010s - loss: 0.1397 - accu\n",
      "Epoch 452/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1338 - accuracy: 0.4907\n",
      "Epoch 453/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1343 - accuracy: 0.4905\n",
      "Epoch 454/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1348 - accuracy: 0.4906\n",
      "Epoch 455/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1366 - accuracy: 0.49041s - los\n",
      "Epoch 456/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1411 - accuracy: 0.4903\n",
      "Epoch 457/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1396 - accuracy: 0.4900\n",
      "Epoch 458/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1334 - accuracy: 0.4906\n",
      "Epoch 459/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1355 - accuracy: 0.4905\n",
      "Epoch 460/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1341 - accuracy: 0.49061s - los\n",
      "Epoch 461/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1356 - accuracy: 0.4905\n",
      "Epoch 462/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1330 - accuracy: 0.49060s - loss: 0.1331 - accuracy: \n",
      "Epoch 463/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1433 - accuracy: 0.4899\n",
      "Epoch 464/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1364 - accuracy: 0.4905\n",
      "Epoch 465/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1365 - accuracy: 0.4905\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1350 - accuracy: 0.4904\n",
      "Epoch 467/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1319 - accuracy: 0.4907\n",
      "Epoch 468/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1384 - accuracy: 0.4904\n",
      "Epoch 469/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1359 - accuracy: 0.4902\n",
      "Epoch 470/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1357 - accuracy: 0.4904\n",
      "Epoch 471/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1332 - accuracy: 0.4906\n",
      "Epoch 472/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1296 - accuracy: 0.4911\n",
      "Epoch 473/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1314 - accuracy: 0.4908\n",
      "Epoch 474/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1397 - accuracy: 0.4901\n",
      "Epoch 475/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1345 - accuracy: 0.4905\n",
      "Epoch 476/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1299 - accuracy: 0.4909\n",
      "Epoch 477/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1335 - accuracy: 0.4906\n",
      "Epoch 478/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1352 - accuracy: 0.4904\n",
      "Epoch 479/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1341 - accuracy: 0.4906\n",
      "Epoch 480/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1309 - accuracy: 0.4909\n",
      "Epoch 481/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1350 - accuracy: 0.4905\n",
      "Epoch 482/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1317 - accuracy: 0.4908\n",
      "Epoch 483/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1325 - accuracy: 0.4908\n",
      "Epoch 484/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1378 - accuracy: 0.4902\n",
      "Epoch 485/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1346 - accuracy: 0.4905\n",
      "Epoch 486/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1371 - accuracy: 0.4904\n",
      "Epoch 487/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1319 - accuracy: 0.49071s - loss:\n",
      "Epoch 488/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1280 - accuracy: 0.4910\n",
      "Epoch 489/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1333 - accuracy: 0.4906\n",
      "Epoch 490/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1311 - accuracy: 0.4909\n",
      "Epoch 491/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1364 - accuracy: 0.4903\n",
      "Epoch 492/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1301 - accuracy: 0.4910\n",
      "Epoch 493/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1354 - accuracy: 0.4902\n",
      "Epoch 494/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1253 - accuracy: 0.4913\n",
      "Epoch 495/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1263 - accuracy: 0.4911\n",
      "Epoch 496/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1367 - accuracy: 0.4902\n",
      "Epoch 497/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1307 - accuracy: 0.4906\n",
      "Epoch 498/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1339 - accuracy: 0.4904\n",
      "Epoch 499/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1317 - accuracy: 0.4905\n",
      "Epoch 500/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1261 - accuracy: 0.49110s - loss: 0.1260 - accuracy: 0.\n",
      "Epoch 501/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1347 - accuracy: 0.4905\n",
      "Epoch 502/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1240 - accuracy: 0.4911\n",
      "Epoch 503/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1309 - accuracy: 0.4908\n",
      "Epoch 504/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1291 - accuracy: 0.4908\n",
      "Epoch 505/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1249 - accuracy: 0.4910\n",
      "Epoch 506/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1281 - accuracy: 0.4908\n",
      "Epoch 507/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1262 - accuracy: 0.4911\n",
      "Epoch 508/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1236 - accuracy: 0.4910\n",
      "Epoch 509/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1310 - accuracy: 0.4906\n",
      "Epoch 510/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1258 - accuracy: 0.4908\n",
      "Epoch 511/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1261 - accuracy: 0.4910\n",
      "Epoch 512/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1309 - accuracy: 0.4906\n",
      "Epoch 513/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1238 - accuracy: 0.4913\n",
      "Epoch 514/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1187 - accuracy: 0.4916\n",
      "Epoch 515/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1214 - accuracy: 0.4914\n",
      "Epoch 516/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1249 - accuracy: 0.4909\n",
      "Epoch 517/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1327 - accuracy: 0.49060s - loss: 0.1329 - ac\n",
      "Epoch 518/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1301 - accuracy: 0.4906\n",
      "Epoch 519/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1228 - accuracy: 0.4914\n",
      "Epoch 520/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1217 - accuracy: 0.4914: 26s - loss: 0.1207 - accuracy: - ETA: 26s - loss: 0.1200 - a - ETA: 24s - loss: 0.120\n",
      "Epoch 521/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1239 - accuracy: 0.4911\n",
      "Epoch 522/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1237 - accuracy: 0.4911\n",
      "Epoch 523/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1251 - accuracy: 0.49110s - loss: 0.1250 - accu\n",
      "Epoch 524/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1334 - accuracy: 0.49041s - l\n",
      "Epoch 525/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1268 - accuracy: 0.4909\n",
      "Epoch 526/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1184 - accuracy: 0.4914: 29s - loss: 0.1\n",
      "Epoch 527/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1181 - accuracy: 0.4917\n",
      "Epoch 528/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1254 - accuracy: 0.49103s - los\n",
      "Epoch 529/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1259 - accuracy: 0.4911\n",
      "Epoch 530/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1266 - accuracy: 0.4908\n",
      "Epoch 531/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1237 - accuracy: 0.4912\n",
      "Epoch 532/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1196 - accuracy: 0.4915\n",
      "Epoch 533/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1227 - accuracy: 0.4911\n",
      "Epoch 534/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1246 - accuracy: 0.4910\n",
      "Epoch 535/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1205 - accuracy: 0.4913\n",
      "Epoch 536/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1254 - accuracy: 0.4910\n",
      "Epoch 537/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1263 - accuracy: 0.4909\n",
      "Epoch 538/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1198 - accuracy: 0.4914\n",
      "Epoch 539/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1182 - accuracy: 0.49161s - loss: 0.1174  - ETA: 0s - loss: 0.1179 - ac\n",
      "Epoch 540/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1229 - accuracy: 0.49101s\n",
      "Epoch 541/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1192 - accuracy: 0.4914\n",
      "Epoch 542/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1160 - accuracy: 0.4918\n",
      "Epoch 543/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1227 - accuracy: 0.4911 ETA: 0s - loss: 0.122\n",
      "Epoch 544/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1242 - accuracy: 0.49115s - los\n",
      "Epoch 545/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1204 - accuracy: 0.4914\n",
      "Epoch 546/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1239 - accuracy: 0.4911\n",
      "Epoch 547/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1243 - accuracy: 0.4909\n",
      "Epoch 548/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1165 - accuracy: 0.4917\n",
      "Epoch 549/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1164 - accuracy: 0.4917\n",
      "Epoch 550/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1163 - accuracy: 0.4917\n",
      "Epoch 551/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1241 - accuracy: 0.4910: 42s - loss: 0.1039 - accura - ETA: 41s - loss: 0.1219 - accurac - ETA: 40s - loss: 0.1 -  - ETA: 30s - loss: 0.11 - ETA: 28s - loss: 0.1179 - E\n",
      "Epoch 552/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1168 - accuracy: 0.4915\n",
      "Epoch 553/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1160 - accuracy: 0.4916\n",
      "Epoch 554/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1193 - accuracy: 0.49140s - loss: 0.1191 - accura\n",
      "Epoch 555/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1188 - accuracy: 0.4914 ETA: 13s - loss: 0.1211 - accuracy: 0.49 - ETA: 13s - los\n",
      "Epoch 556/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1149 - accuracy: 0.4917\n",
      "Epoch 557/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1173 - accuracy: 0.4915\n",
      "Epoch 558/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1200 - accuracy: 0.49151s - loss: 0\n",
      "Epoch 559/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1207 - accuracy: 0.4913: 41s - loss: 0.1075 - accuracy: - ETA: 2s - loss: 0.1204 - accu\n",
      "Epoch 560/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1198 - accuracy: 0.49134s - los - ETA: 3s - los\n",
      "Epoch 561/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1139 - accuracy: 0.4918\n",
      "Epoch 562/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1161 - accuracy: 0.4918\n",
      "Epoch 563/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1156 - accuracy: 0.4915 ETA: 19s - loss: 0.1154 -  - ETA: 13s - loss: - ETA: 4s - loss: 0.1165 - accuracy:  - ETA: 4s - loss: 0.1162 - accu - ETA: \n",
      "Epoch 564/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1213 - accuracy: 0.4912\n",
      "Epoch 565/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1153 - accuracy: 0.4916: 35s - loss: 0.1139 - accura - ETA: 34s - loss: 0.1149 - - ETA: 32s - l - ETA: 25s - loss: 0.1148 - accurac - ETA: 25s - loss: 0.1138  - ETA - ETA: 1 - - E - ETA: 1s - los\n",
      "Epoch 566/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1177 - accuracy: 0.4913\n",
      "Epoch 567/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1161 - accuracy: 0.49161s - loss: 0\n",
      "Epoch 568/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1168 - accuracy: 0.4917\n",
      "Epoch 569/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1175 - accuracy: 0.4915\n",
      "Epoch 570/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1176 - accuracy: 0.4914\n",
      "Epoch 571/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1133 - accuracy: 0.4919: 32s - loss: 0.1127 - a\n",
      "Epoch 572/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1136 - accuracy: 0.4918\n",
      "Epoch 573/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1246 - accuracy: 0.4911\n",
      "Epoch 574/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1192 - accuracy: 0.4914: 32s - loss: 0.1156 - acc - ETA: 8s - - ETA: 6s - loss: 0.1174 - ac\n",
      "Epoch 575/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1159 - accuracy: 0.4916: 29s - loss: 0.1174 - accuracy: 0.4 - ETA: 29s - loss: 0.1172\n",
      "Epoch 576/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1143 - accuracy: 0.4918\n",
      "Epoch 577/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1193 - accuracy: 0.49152s - loss: 0.1191 - ac\n",
      "Epoch 578/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1095 - accuracy: 0.4921\n",
      "Epoch 579/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1134 - accuracy: 0.4920\n",
      "Epoch 580/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1140 - accuracy: 0.4918\n",
      "Epoch 581/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1184 - accuracy: 0.4914: 37s - lo - ETA: 17\n",
      "Epoch 582/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1200 - accuracy: 0.4912: 40s - loss: 0.1106 - accur - ETA: 40s - l - ETA: 37s - l - ETA: 3s - loss: 0.1211 - accu - ETA: 0s - loss: 0.1204 - accu - ETA: 0s - loss: 0.1202 - accura\n",
      "Epoch 583/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1115 - accuracy: 0.4919\n",
      "Epoch 584/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1116 - accuracy: 0.4920\n",
      "Epoch 585/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1181 - accuracy: 0.4916\n",
      "Epoch 586/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1124 - accuracy: 0.4920 - ETA - ETA: 2s - loss: 0.1130 - accuracy\n",
      "Epoch 587/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1143 - accuracy: 0.4919: 30s - loss: - ETA: 19s - loss: 0.1144 - accu\n",
      "Epoch 588/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1163 - accuracy: 0.49155s - loss: 0.1 - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0.1\n",
      "Epoch 589/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1183 - accuracy: 0.4915\n",
      "Epoch 590/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1157 - accuracy: 0.49162s - loss: 0.1164 -  - ETA: 1s - loss: 0.1160 -  - ETA: 0s - loss: 0.1159 - ac - ETA: 0s - loss: 0.1155 - accuracy: \n",
      "Epoch 591/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1105 - accuracy: 0.4921\n",
      "Epoch 592/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1098 - accuracy: 0.4921\n",
      "Epoch 593/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1154 - accuracy: 0.49190s - loss: 0.1156 - accu\n",
      "Epoch 594/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1189 - accuracy: 0.4913\n",
      "Epoch 595/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1123 - accuracy: 0.4919\n",
      "Epoch 596/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1136 - accuracy: 0.4919\n",
      "Epoch 597/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1135 - accuracy: 0.4917\n",
      "Epoch 598/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1118 - accuracy: 0.4920\n",
      "Epoch 599/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1135 - accuracy: 0.4918\n",
      "Epoch 600/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1144 - accuracy: 0.4917\n",
      "Epoch 601/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1136 - accuracy: 0.49170s - loss: 0.1134 - accura\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1161 - accuracy: 0.4918: 21s - loss: 0.1165 - ac - ETA: 19s - - ETA: 16s - loss: 0.\n",
      "Epoch 603/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1154 - accuracy: 0.4915\n",
      "Epoch 604/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1115 - accuracy: 0.4918\n",
      "Epoch 605/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1102 - accuracy: 0.4920\n",
      "Epoch 606/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1117 - accuracy: 0.4918\n",
      "Epoch 607/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1136 - accuracy: 0.4917: 37s - loss: 0.1036 - accuracy: - ETA: 37s - loss: 0.105 - ETA: 35s - loss: 0.1051 - accuracy: 0.490 - ETA: 35s - loss: 0.1044 - accurac - ETA: 34\n",
      "Epoch 608/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1173 - accuracy: 0.4913: 11s - loss: 0.1161 - accura - ET - ETA: 2s - loss: 0.1166 - accuracy: \n",
      "Epoch 609/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1111 - accuracy: 0.4919:\n",
      "Epoch 610/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1092 - accuracy: 0.4924: 42s - loss - ETA: 36s -  - ETA: 28s - loss: 0.1119 - accura - ETA: 28s - los - ETA: 25s - lo -\n",
      "Epoch 611/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1131 - accuracy: 0.4919\n",
      "Epoch 612/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1160 - accuracy: 0.4914\n",
      "Epoch 613/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1127 - accuracy: 0.4919TA: 0s - loss: 0.1125 - accuracy\n",
      "Epoch 614/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1129 - accuracy: 0.4918 ET - ETA: 19s - loss: 0.1097 - accuracy: 0. - ETA: 19s - loss: 0.1097 - accuracy: - ETA: 18s - lo - ETA: 16s - loss: 0.1094 - accu\n",
      "Epoch 615/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1135 - accuracy: 0.49180s - loss: 0.113\n",
      "Epoch 616/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1094 - accuracy: 0.4922\n",
      "Epoch 617/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1131 - accuracy: 0.4919\n",
      "Epoch 618/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1107 - accuracy: 0.4920: 4 - ETA: 29s - l - ETA: 26s - loss: 0.1066 - accuracy: 0.493 - ETA: 26s - loss: 0.1069 - ET - ETA: 21s - loss: 0.1091 - accuracy:  - ETA: 20s - loss: 0.1081 - accuracy: 0.492 - ETA: 9s - - - ETA: \n",
      "Epoch 619/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1157 - accuracy: 0.4915\n",
      "Epoch 620/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1186 - accuracy: 0.4913: 41s -  - ETA: 13s - loss: 0.1182 - accu - ETA: 12s -  - E - E\n",
      "Epoch 621/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1099 - accuracy: 0.4921\n",
      "Epoch 622/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1081 - accuracy: 0.4923TA: 2s - loss: 0.1078 - ac - ETA: 1s - loss: 0.1082 - accuracy:  - ETA: 1s - loss:\n",
      "Epoch 623/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1089 - accuracy: 0.4921\n",
      "Epoch 624/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1102 - accuracy: 0.4921\n",
      "Epoch 625/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1117 - accuracy: 0.4920\n",
      "Epoch 626/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1125 - accuracy: 0.4918\n",
      "Epoch 627/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1100 - accuracy: 0.49211s -\n",
      "Epoch 628/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1111 - accuracy: 0.49190s - loss: 0.1117 \n",
      "Epoch 629/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1136 - accuracy: 0.4918\n",
      "Epoch 630/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1124 - accuracy: 0.4920\n",
      "Epoch 631/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1176 - accuracy: 0.49140s - loss: 0.1172 - ac\n",
      "Epoch 632/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1146 - accuracy: 0.49161s - loss: 0.1133 - accuracy:  - ETA: 1s - los\n",
      "Epoch 633/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1099 - accuracy: 0.4920: 43 - ETA: 39s - l - ETA: 24s - loss - ETA: 13s - loss: 0.1096 - accuracy: 0.  - ETA: 7s - loss: 0.1098 - accuracy: 0. - ETA: 7s - - ETA\n",
      "Epoch 634/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1114 - accuracy: 0.49210s - loss: 0.1107 - \n",
      "Epoch 635/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1105 - accuracy: 0.4920: 20s - - ETA: 17s - loss:  - ETA: 0s - loss: 0.1104 - accuracy: 0.\n",
      "Epoch 636/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1104 - accuracy: 0.4920: 29s - los\n",
      "Epoch 637/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1097 - accuracy: 0.4921 ETA: 3s - loss: 0.1106 - ac - ETA: 0s - loss: 0.1097 - accu\n",
      "Epoch 638/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1165 - accuracy: 0.4916: 19s - loss: 0. - ETA: 17s - loss: 0.1119 - accuracy: 0.49 - ETA: 17s - loss - ETA: 1s - loss: 0.1 - ETA: 0s - loss: 0.1\n",
      "Epoch 639/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1131 - accuracy: 0.4917: 18s - loss: 0.1116  - ETA: 16s - loss: 0.1102 - accuracy - ETA: 15s - loss - ETA: 3s - l\n",
      "Epoch 640/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1097 - accuracy: 0.49220s - loss: 0.1097 - accu\n",
      "Epoch 641/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1114 - accuracy: 0.49202s - loss: 0.111 - E\n",
      "Epoch 642/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1114 - accuracy: 0.4918\n",
      "Epoch 643/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1088 - accuracy: 0.4923\n",
      "Epoch 644/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1084 - accuracy: 0.4920\n",
      "Epoch 645/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1071 - accuracy: 0.49222s - loss: 0.1075  - ETA: 1s\n",
      "Epoch 646/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1141 - accuracy: 0.4916\n",
      "Epoch 647/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1112 - accuracy: 0.4918\n",
      "Epoch 648/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1104 - accuracy: 0.4919\n",
      "Epoch 649/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1083 - accuracy: 0.4922\n",
      "Epoch 650/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1095 - accuracy: 0.4921\n",
      "Epoch 651/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1090 - accuracy: 0.49220s - loss: 0.1091 \n",
      "Epoch 652/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1112 - accuracy: 0.4920\n",
      "Epoch 653/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1158 - accuracy: 0.4916\n",
      "Epoch 654/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1116 - accuracy: 0.4918\n",
      "Epoch 655/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1094 - accuracy: 0.4920\n",
      "Epoch 656/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1095 - accuracy: 0.4920\n",
      "Epoch 657/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1107 - accuracy: 0.4920\n",
      "Epoch 658/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1114 - accuracy: 0.4918\n",
      "Epoch 659/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1098 - accuracy: 0.4919\n",
      "Epoch 660/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1056 - accuracy: 0.49231s\n",
      "Epoch 661/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1075 - accuracy: 0.4924\n",
      "Epoch 662/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1132 - accuracy: 0.4917\n",
      "Epoch 663/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1085 - accuracy: 0.49221s - loss: 0.1084 -  - ETA: 1s - loss: 0\n",
      "Epoch 664/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1088 - accuracy: 0.4920\n",
      "Epoch 665/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1098 - accuracy: 0.4919\n",
      "Epoch 666/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1101 - accuracy: 0.4919\n",
      "Epoch 667/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1104 - accuracy: 0.4919\n",
      "Epoch 668/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1063 - accuracy: 0.4923\n",
      "Epoch 669/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1064 - accuracy: 0.4923\n",
      "Epoch 670/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1094 - accuracy: 0.4920\n",
      "Epoch 671/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1128 - accuracy: 0.4917\n",
      "Epoch 672/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1089 - accuracy: 0.4920\n",
      "Epoch 673/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1090 - accuracy: 0.4922\n",
      "Epoch 674/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1068 - accuracy: 0.4923\n",
      "Epoch 675/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1099 - accuracy: 0.4920\n",
      "Epoch 676/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1106 - accuracy: 0.4920\n",
      "Epoch 677/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1083 - accuracy: 0.4920\n",
      "Epoch 678/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1071 - accuracy: 0.4923\n",
      "Epoch 679/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1095 - accuracy: 0.4920\n",
      "Epoch 680/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1110 - accuracy: 0.4918\n",
      "Epoch 681/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1091 - accuracy: 0.4921\n",
      "Epoch 682/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1061 - accuracy: 0.4923\n",
      "Epoch 683/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1073 - accuracy: 0.4922\n",
      "Epoch 684/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1116 - accuracy: 0.4918\n",
      "Epoch 685/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1086 - accuracy: 0.4920\n",
      "Epoch 686/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1059 - accuracy: 0.4921\n",
      "Epoch 687/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1086 - accuracy: 0.4919\n",
      "Epoch 688/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1109 - accuracy: 0.4918\n",
      "Epoch 689/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1055 - accuracy: 0.4922\n",
      "Epoch 690/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1112 - accuracy: 0.4918\n",
      "Epoch 691/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1105 - accuracy: 0.4919\n",
      "Epoch 692/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1052 - accuracy: 0.4924\n",
      "Epoch 693/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1082 - accuracy: 0.49210s - loss: 0.1081 - ac\n",
      "Epoch 694/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1071 - accuracy: 0.4923\n",
      "Epoch 695/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1084 - accuracy: 0.4922\n",
      "Epoch 696/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1070 - accuracy: 0.4922\n",
      "Epoch 697/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1088 - accuracy: 0.4920\n",
      "Epoch 698/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1091 - accuracy: 0.4919\n",
      "Epoch 699/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.1075 - accuracy: 0.4921\n",
      "Epoch 700/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1078 - accuracy: 0.4921\n",
      "Epoch 701/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1047 - accuracy: 0.4924\n",
      "Epoch 702/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1061 - accuracy: 0.49231s - l\n",
      "Epoch 703/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1097 - accuracy: 0.49190s - loss: 0.1096 - \n",
      "Epoch 704/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1078 - accuracy: 0.4920\n",
      "Epoch 705/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1063 - accuracy: 0.4921\n",
      "Epoch 706/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.1085 - accuracy: 0.4921\n",
      "Epoch 707/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1099 - accuracy: 0.4919\n",
      "Epoch 708/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1019 - accuracy: 0.4926\n",
      "Epoch 709/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1033 - accuracy: 0.4925\n",
      "Epoch 710/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1081 - accuracy: 0.4918\n",
      "Epoch 711/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.1049 - accuracy: 0.4921\n",
      "Epoch 712/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1045 - accuracy: 0.4923\n",
      "Epoch 713/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1059 - accuracy: 0.49230s - loss: 0.1062 - accuracy\n",
      "Epoch 714/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1051 - accuracy: 0.4924\n",
      "Epoch 715/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1061 - accuracy: 0.4921\n",
      "Epoch 716/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1116 - accuracy: 0.4917\n",
      "Epoch 717/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1078 - accuracy: 0.4921\n",
      "Epoch 718/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1046 - accuracy: 0.4923\n",
      "Epoch 719/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1057 - accuracy: 0.4922\n",
      "Epoch 720/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.1069 - accuracy: 0.4922\n",
      "Epoch 721/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1094 - accuracy: 0.4919\n",
      "Epoch 722/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1072 - accuracy: 0.4921\n",
      "Epoch 723/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1031 - accuracy: 0.4924\n",
      "Epoch 724/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1031 - accuracy: 0.4925\n",
      "Epoch 725/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.1056 - accuracy: 0.4922\n",
      "Epoch 726/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1070 - accuracy: 0.49201s - los\n",
      "Epoch 727/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1065 - accuracy: 0.4922\n",
      "Epoch 728/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1049 - accuracy: 0.49221s - loss: 0.104 - ETA: 0s - loss: 0.1052 - \n",
      "Epoch 729/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1051 - accuracy: 0.4923\n",
      "Epoch 730/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1023 - accuracy: 0.49243s - loss:\n",
      "Epoch 731/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1049 - accuracy: 0.4923\n",
      "Epoch 732/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1127 - accuracy: 0.4915\n",
      "Epoch 733/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1041 - accuracy: 0.4922: 30s - loss: 0.10 - ETA: 0s - loss: 0.1040 \n",
      "Epoch 734/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1029 - accuracy: 0.4925\n",
      "Epoch 735/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1055 - accuracy: 0.4924\n",
      "Epoch 736/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1061 - accuracy: 0.49211s\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1004 - accuracy: 0.49260s - loss: 0.1000 - accuracy\n",
      "Epoch 738/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1083 - accuracy: 0.49190s - loss: 0.1085 - accuracy: 0.49 - ETA: 0s - loss: 0.1085 - accu\n",
      "Epoch 739/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1058 - accuracy: 0.4923\n",
      "Epoch 740/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1035 - accuracy: 0.4925\n",
      "Epoch 741/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1104 - accuracy: 0.4916\n",
      "Epoch 742/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1040 - accuracy: 0.4923\n",
      "Epoch 743/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1050 - accuracy: 0.4922\n",
      "Epoch 744/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1036 - accuracy: 0.4923: 17s - - ETA: \n",
      "Epoch 745/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1027 - accuracy: 0.4925: 30s - loss: 0.1032  - ETA: - ETA - ETA: 1s - los\n",
      "Epoch 746/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1061 - accuracy: 0.4920\n",
      "Epoch 747/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1027 - accuracy: 0.4924\n",
      "Epoch 748/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1039 - accuracy: 0.49220s - loss: 0.1\n",
      "Epoch 749/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1054 - accuracy: 0.4921: 15s - - ETA: 0s - loss: 0.1\n",
      "Epoch 750/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1044 - accuracy: 0.49201s - loss: - ETA: 0s - loss: 0.1044 - accuracy: \n",
      "Epoch 751/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.1044 - accuracy: 0.4921: 22s - loss\n",
      "Epoch 752/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1005 - accuracy: 0.4923\n",
      "Epoch 753/1000\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.1040 - accuracy: 0.49231s -\n",
      "Epoch 754/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1029 - accuracy: 0.4922\n",
      "Epoch 755/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1006 - accuracy: 0.4924\n",
      "Epoch 756/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1014 - accuracy: 0.49230s - loss: 0.1014 - accuracy: 0.\n",
      "Epoch 757/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1025 - accuracy: 0.4922\n",
      "Epoch 758/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1044 - accuracy: 0.4919: 32s - loss: 0.1018 - accu - E\n",
      "Epoch 759/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1038 - accuracy: 0.4920\n",
      "Epoch 760/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.0992 - accuracy: 0.4924\n",
      "Epoch 761/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0991 - accuracy: 0.4924\n",
      "Epoch 762/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1050 - accuracy: 0.49200s - loss: 0.1050 - accuracy: 0.\n",
      "Epoch 763/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1014 - accuracy: 0.4922\n",
      "Epoch 764/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.0994 - accuracy: 0.4922\n",
      "Epoch 765/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1007 - accuracy: 0.4921\n",
      "Epoch 766/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0995 - accuracy: 0.4922\n",
      "Epoch 767/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1015 - accuracy: 0.4921\n",
      "Epoch 768/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0981 - accuracy: 0.4924\n",
      "Epoch 769/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0998 - accuracy: 0.4921\n",
      "Epoch 770/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0992 - accuracy: 0.4923\n",
      "Epoch 771/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0962 - accuracy: 0.49240s - loss: 0.0962 \n",
      "Epoch 772/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0973 - accuracy: 0.4924: 3 - ETA: 29s - loss: 0.0914 - acc - ETA: 28s - loss: 0. - E - ETA: 22s \n",
      "Epoch 773/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.1011 - accuracy: 0.4920\n",
      "Epoch 774/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0971 - accuracy: 0.4922 - ETA: 2s - - ETA: 1s - loss: 0.0965  - ETA: 0s - loss: 0.0971 - accuracy: 0. - ETA: 0s - loss: 0.0971 - accuracy\n",
      "Epoch 775/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0959 - accuracy: 0.4925: 29s - loss: - ETA: 27s - loss - ETA: 24s - loss: 0.0975 - accuracy: 0. -  - ETA: 20s - loss: 0.09 - ETA: 18s - loss: 0.0974 - accuracy: - ETA: 17s - loss: 0.0966 - accuracy: 0.4 - ETA: 17s - loss: 0.09\n",
      "Epoch 776/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.1011 - accuracy: 0.4921\n",
      "Epoch 777/1000\n",
      "469/469 [==============================] - 43s 93ms/step - loss: 0.1005 - accuracy: 0.4920\n",
      "Epoch 778/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0958 - accuracy: 0.4923: 45s - loss: 0.092 - ETA: 32s - loss: 0.0929 - accuracy: 0. - ETA: - ETA: 28s - loss: 0.0949 - ac - ETA: 27s \n",
      "Epoch 779/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0954 - accuracy: 0.49246s - loss: 0 - - ETA: 1s - loss: 0\n",
      "Epoch 780/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0941 - accuracy: 0.49263s - l\n",
      "Epoch 781/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0965 - accuracy: 0.49230s - loss: 0.0960 - \n",
      "Epoch 782/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0994 - accuracy: 0.4921A: 1s - l\n",
      "Epoch 783/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.1015 - accuracy: 0.49180s - loss: 0.1013 - accura\n",
      "Epoch 784/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0946 - accuracy: 0.4924: 26s - \n",
      "Epoch 785/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0943 - accuracy: 0.4924\n",
      "Epoch 786/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0981 - accuracy: 0.4923\n",
      "Epoch 787/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0960 - accuracy: 0.4924\n",
      "Epoch 788/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0964 - accuracy: 0.4924\n",
      "Epoch 789/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0961 - accuracy: 0.4923\n",
      "Epoch 790/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.1000 - accuracy: 0.4919TA: 27s - loss: 0.09 - ETA: 25s - loss: 0 - ETA: 18s - loss: 0.1012 - accurac - ETA: 17s \n",
      "Epoch 791/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0931 - accuracy: 0.4927: 20s - loss: 0.0923 - accu - ETA: 19s - loss: - ETA: 13s - loss\n",
      "Epoch 792/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.0939 - accuracy: 0.4925\n",
      "Epoch 793/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.0975 - accuracy: 0.4922\n",
      "Epoch 794/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.0976 - accuracy: 0.4922: 33s - los - ETA: 30s - loss: 0.0922 - accurac - ETA: 29s  - ETA: 22s - loss: 0.0942 - ac - ETA: 12s - loss: 0.0966 -\n",
      "Epoch 795/1000\n",
      "469/469 [==============================] - 45s 97ms/step - loss: 0.0952 - accuracy: 0.4924\n",
      "Epoch 796/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0932 - accuracy: 0.4925\n",
      "Epoch 797/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0934 - accuracy: 0.49251s - loss: 0 - ETA: 0s - loss: 0.0928 - ac\n",
      "Epoch 798/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0939 - accuracy: 0.4924\n",
      "Epoch 799/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0909 - accuracy: 0.49271s - loss: 0\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0944 - accuracy: 0.4925: 42s - loss: 0.0772 - accuracy: 0. - ETA: 38 - ETA: 34s - \n",
      "Epoch 801/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0923 - accuracy: 0.49276s - loss: 0.0903  - ETA: \n",
      "Epoch 802/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0959 - accuracy: 0.4925\n",
      "Epoch 803/1000\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.0960 - accuracy: 0.4924: 16s - loss: 0.0920 - accu\n",
      "Epoch 804/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0980 - accuracy: 0.4922: 40s - loss: 0. - ETA: 38s - loss: 0.0930 - accurac - ETA: 3 - ETA - ETA: 25s - loss: 0.0978 - a - ETA: 24s - loss: 0.0992 - accur - ETA: 23s - loss: 0.0982 - accuracy: 0. - ETA: 23s -  - ETA: 11s -  - ETA: 9s - - ETA: 3s -\n",
      "Epoch 805/1000\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 0.0936 - accuracy: 0.49252s - loss: 0.0937 - accura\n",
      "Epoch 806/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0950 - accuracy: 0.49250s - loss: 0.0951 - accura\n",
      "Epoch 807/1000\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0926 - accuracy: 0.49245s\n",
      "Epoch 808/1000\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0914 - accuracy: 0.49260s - loss: 0.0915 - accu\n",
      "Epoch 809/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0974 - accuracy: 0.4922\n",
      "Epoch 810/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0957 - accuracy: 0.4922\n",
      "Epoch 811/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0958 - accuracy: 0.4923\n",
      "Epoch 812/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0939 - accuracy: 0.4925\n",
      "Epoch 813/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0927 - accuracy: 0.4925\n",
      "Epoch 814/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0923 - accuracy: 0.4925\n",
      "Epoch 815/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0899 - accuracy: 0.4929\n",
      "Epoch 816/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0949 - accuracy: 0.4924\n",
      "Epoch 817/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0935 - accuracy: 0.4925\n",
      "Epoch 818/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0983 - accuracy: 0.4921\n",
      "Epoch 819/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0940 - accuracy: 0.4925\n",
      "Epoch 820/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0928 - accuracy: 0.4926\n",
      "Epoch 821/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0910 - accuracy: 0.4926\n",
      "Epoch 822/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.0966 - accuracy: 0.4925\n",
      "Epoch 823/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0947 - accuracy: 0.4922\n",
      "Epoch 824/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0906 - accuracy: 0.4927\n",
      "Epoch 825/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0902 - accuracy: 0.4926\n",
      "Epoch 826/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0902 - accuracy: 0.4927\n",
      "Epoch 827/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0905 - accuracy: 0.4927\n",
      "Epoch 828/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0938 - accuracy: 0.4925\n",
      "Epoch 829/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0988 - accuracy: 0.4920\n",
      "Epoch 830/1000\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0934 - accuracy: 0.49250s - loss: 0.0935 - accura\n",
      "Epoch 831/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0929 - accuracy: 0.4924\n",
      "Epoch 832/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0913 - accuracy: 0.4925\n",
      "Epoch 833/1000\n",
      "469/469 [==============================] - 46s 98ms/step - loss: 0.0928 - accuracy: 0.4925\n",
      "Epoch 834/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0928 - accuracy: 0.4925\n",
      "Epoch 835/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0902 - accuracy: 0.4927\n",
      "Epoch 836/1000\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 0.0895 - accuracy: 0.4929\n",
      "Epoch 837/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0947 - accuracy: 0.4923\n",
      "Epoch 838/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0945 - accuracy: 0.4922\n",
      "Epoch 839/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0898 - accuracy: 0.4928\n",
      "Epoch 840/1000\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.0902 - accuracy: 0.4927 1s - l\n",
      "Epoch 841/1000\n",
      "469/469 [==============================] - 45s 96ms/step - loss: 0.0943 - accuracy: 0.4923\n",
      "Epoch 842/1000\n",
      "469/469 [==============================] - 48s 103ms/step - loss: 0.0990 - accuracy: 0.4918\n",
      "Epoch 843/1000\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0954 - accuracy: 0.4921\n",
      "Epoch 844/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0916 - accuracy: 0.4925\n",
      "Epoch 845/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0906 - accuracy: 0.4926\n",
      "Epoch 846/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0916 - accuracy: 0.4928\n",
      "Epoch 847/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0930 - accuracy: 0.4924\n",
      "Epoch 848/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0894 - accuracy: 0.4927\n",
      "Epoch 849/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0898 - accuracy: 0.4927\n",
      "Epoch 850/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0902 - accuracy: 0.4927\n",
      "Epoch 851/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0896 - accuracy: 0.4927\n",
      "Epoch 852/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0913 - accuracy: 0.4925\n",
      "Epoch 853/1000\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.0900 - accuracy: 0.4926\n",
      "Epoch 854/1000\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0873 - accuracy: 0.4928\n",
      "Epoch 855/1000\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0940 - accuracy: 0.4922\n",
      "Epoch 856/1000\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.0931 - accuracy: 0.4923\n",
      "Epoch 857/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0910 - accuracy: 0.4925\n",
      "Epoch 858/1000\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0917 - accuracy: 0.4924\n",
      "Epoch 859/1000\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.0878 - accuracy: 0.4927s - l - E - ETA: 0s - loss: 0.087\n",
      "Epoch 860/1000\n",
      " 21/469 [>.............................] - ETA: 49s - loss: 0.0866 - accuracy: 0.4970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-75153b237d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# , validation_data=(texts_test, values_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Diploma\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(texts_train, values_train, batch_size=512, epochs=1000) # , validation_data=(texts_test, values_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9efe1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text):\n",
    "    model_input = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=max_len, padding=\"post\")\n",
    "    model_output = model.predict(model_input)[0][0]\n",
    "    return f\"Sentence is positive for {(model_output / 4) * 100} %\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "040eb0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentence is positive for 99.01155233383179 %'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(\"This party was an explosion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9ff482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_6B_set_LSTM_1_hidden_layer\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_6B_set_LSTM_1_hidden_layer\\assets\n"
     ]
    }
   ],
   "source": [
    "with open('tokenizer_1_6B_set.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "model.save('model_1_6B_set_LSTM_1_hidden_layer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}